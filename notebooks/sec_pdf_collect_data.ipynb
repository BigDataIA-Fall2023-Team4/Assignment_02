{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Collect data from SEC.gov form PDF Files\n",
        "\n"
      ],
      "metadata": {
        "id": "bJmUdyw2wwzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this project is to build a question-answering model using content extracted from forms available on sec.gov (U.S. Securities and Exchange Commission). While base GPT-3 models excel at answering questions when the answers are directly within the text, they often generate speculative answers when the information is not present in the given context.\n",
        "\n",
        "To create a model that answers questions only when there's ample context, we begin by constructing a dataset of questions and answers derived from text paragraphs. To train the model to discern when answers are genuinely present, we introduce adversarial examples. These examples involve questions that do not align with the context. In such situations, we instruct the model to respond with \"Insufficient context for answering the question.\"\n",
        "\n",
        "Our project will unfold across three notebooks:\n",
        "\n",
        "> **Data Collection (This Notebook):** In this initial notebook, we concentrate on gathering data that was not part of GPT-3's pre-training. We selected data from sec.gov and downloaded various PDF forms to compile our dataset. We then partitioned the content into smaller token-based segments, which will serve as the context for posing and addressing questions.\n",
        "\n",
        "\n",
        "\n",
        "> **Question Asking and Answering:** In the second notebook, we will leverage the Davinci-instruct model to ask questions based on SEC forms and generate answers based on the provided context.\n",
        "\n",
        "> **Adversarial Questions and Discriminator Model:** In the third notebook, we will employ the dataset containing context, questions, and answers to create adversarial pairs of questions and context where the question was not originally generated from that context. In these scenarios, the model will be prompted to respond with \"Insufficient context for answering the question.\" Additionally, we will train a discriminator model capable of predicting whether a question can be answered based on the provided context. This step will further enhance the model's ability to discern suitable responses based on context."
      ],
      "metadata": {
        "id": "36dUqPnJ6qbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Dependencies"
      ],
      "metadata": {
        "id": "IMrtKxnCzWPU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-oPL3XrfKsU",
        "outputId": "dd354e19-12f8-4624-d8a3-533543a9ee80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.16.4-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.16.4\n"
          ]
        }
      ],
      "source": [
        " !pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHLBH3jIEvpt",
        "outputId": "e87ecb69-6a48-49d5-e03e-94c1596a83e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Parsing using PyPDF"
      ],
      "metadata": {
        "id": "0yt-XMw1zdtW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PyPDF library allows us to work with PDF files. It provides a range of functionalities for reading, manipulating, and writing PDF documents. One of its key features is the ability to parse and extract content from PDF files using the PdfReader(), this feature has been utilized to extract PDF content in this exercise. This feature can be handy for tasks like extracting text, images, and metadata from PDFs. This library simplifies working with PDFs in Python, making it a valuable tool for tasks involving PDF file processing and analysis."
      ],
      "metadata": {
        "id": "GKyEp2Ey8OGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "def fetch_pdf_from_url(url):\n",
        "    # Send an HTTP GET request to the provided URL.\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful (status code 200).\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(\"Failed to fetch the PDF.\")\n",
        "\n",
        "    # Return the content of the PDF as a BytesIO object.\n",
        "    return BytesIO(response.content)\n",
        "\n",
        "def parse_pdf_with_pypdf(local_filename):\n",
        "    # Create a PdfReader object to read the PDF file.\n",
        "    reader = PdfReader(local_filename)\n",
        "\n",
        "    # Get the total number of pages in the PDF.\n",
        "    number_of_pages = len(reader.pages)\n",
        "\n",
        "    # Initialize an empty string to store the extracted text.\n",
        "    text = ''\n",
        "\n",
        "    # Iterate through each page in the PDF and extract its text.\n",
        "    for i in range(number_of_pages):\n",
        "        page = reader.pages[i]\n",
        "        text = text + page.extract_text()\n",
        "\n",
        "    # Return the concatenated text extracted from all pages.\n",
        "    return text"
      ],
      "metadata": {
        "id": "yR_LFn18fwsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the user to enter a PDF file URL for processing and store it in the pdf_url variable.\n",
        "pdf_url = input('Enter the file URL for processing: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhNc4t0wjLu6",
        "outputId": "ad0a222d-5706-46fe-b942-760ac1452df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the file URL for processing: https://www.sec.gov/files/form1-n.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use 'fetch_pdf_from_url' to fetch the PDF content from the provided URL and store in memory\n",
        "pdf_in_memory = fetch_pdf_from_url(pdf_url)\n",
        "# Use 'parse_pdf_with_pypdf' to parse the content of the PDF and store the parsed content in a string variable.\n",
        "pdf_content = parse_pdf_with_pypdf(pdf_in_memory)"
      ],
      "metadata": {
        "id": "5abjkbepiQ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data and storing in a dataframe"
      ],
      "metadata": {
        "id": "OrtF2Vrx8tmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parsed pdf content has been splitted as per the line breaks and then concatenated back within the limit of maximum token to create content for qa. The final content is stored in a dataframe along with the total number of tokens with in content."
      ],
      "metadata": {
        "id": "Odfpahep9AL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "import pandas as pd\n",
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "# Initialize the GPT-2 tokenizer\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    \"\"\"Count the number of tokens in a string\"\"\"\n",
        "    return len(tokenizer.encode(text, add_special_tokens=False))\n",
        "\n",
        "def split_context(text: str) -> DataFrame:\n",
        "  \"\"\"\n",
        "  The function takes a text string as input and returns a DataFrame containing\n",
        "  the token count and content of each paragraph.\n",
        "  \"\"\"\n",
        "    # Initialize a dictionary to store data for the DataFrame\n",
        "    data = {\n",
        "        \"num_tokens\": [],  # List to store the token count for each paragraph\n",
        "        \"content\": []      # List to store the content of each paragraph\n",
        "    }\n",
        "    current_row = \"\"  # Initialize an empty string to keep track of the current paragraph\n",
        "    current_token_count = 0  # Initialize the token count for the current paragraph\n",
        "\n",
        "    # Split the input text into paragraphs using '\\n' as the delimiter\n",
        "    paragraphs = text.split('\\n')\n",
        "\n",
        "    # Iterate through each paragraph in the input text\n",
        "    for paragraph in paragraphs:\n",
        "        # Calculate the token count for the current paragraph using a function count_tokens\n",
        "        token_count = count_tokens(paragraph)\n",
        "\n",
        "        # Append the token count and the content of the current paragraph to the data dictionary\n",
        "        data[\"num_tokens\"].append(token_count)\n",
        "        data[\"content\"].append(paragraph.strip())\n",
        "\n",
        "        # Create a DataFrame using the data dictionary\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_dataframe(df: DataFrame, max_tokens: int) -> DataFrame:\n",
        "    # Initialize variables to keep track of the current row and the concatenated content\n",
        "    current_row = 0\n",
        "    current_content = df.at[0, 'content']\n",
        "    current_num_tokens = df.at[0, 'num_tokens']\n",
        "\n",
        "    # Initialize lists to store the updated data\n",
        "    new_num_tokens = []\n",
        "    new_content = []\n",
        "\n",
        "    # Iterate through the DataFrame\n",
        "    for i in range(1, len(df)):\n",
        "        num_tokens = df.at[i, 'num_tokens']\n",
        "        content = df.at[i, 'content']\n",
        "\n",
        "        # Check if adding the current row would max token limit\n",
        "        if current_num_tokens + num_tokens <= max_tokens:\n",
        "            current_content += ' ' + content\n",
        "            current_num_tokens += num_tokens\n",
        "        else:\n",
        "            # Save the concatenated content and num_tokens for the current row\n",
        "            new_num_tokens.append(current_num_tokens)\n",
        "            new_content.append(current_content)\n",
        "\n",
        "            # Move to the next row\n",
        "            current_row = i\n",
        "            current_content = content\n",
        "            current_num_tokens = num_tokens\n",
        "\n",
        "    # Append the last row\n",
        "    new_num_tokens.append(current_num_tokens)\n",
        "    new_content.append(current_content)\n",
        "\n",
        "    # Create a new DataFrame with the updated values\n",
        "    new_df = pd.DataFrame({'num_tokens': new_num_tokens, 'content': new_content})\n",
        "\n",
        "    return new_df\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "o72E685HEDlb"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the PDF content into smaller chunks, creating a DataFrame\n",
        "df_split = split_context(pdf_content)\n",
        "\n",
        "# Set a maximum number of tokens per chunk\n",
        "max_tokens = 1000\n",
        "\n",
        "# Create a final DataFrame where content is grouped into chunks of up to max_tokens\n",
        "df_final = create_dataframe(df_split, max_tokens)\n",
        "\n",
        "# Display the first few rows of the final DataFrame\n",
        "df_final.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "GIUY4xuFT75A",
        "outputId": "1ee608b1-987d-46e6-cb8d-156a56d92e4d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   num_tokens                                            content\n",
              "0         993  OMB APPROVAL OMB Number: 3235-0554 Expires:  F...\n",
              "1         997  This collection of information has been review...\n",
              "2         986  The exchange consents that service of any civi...\n",
              "3         900  Exhibit D Describe the manner of operation of ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83d70a40-dee4-4aa1-859f-1d7889b1d4d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_tokens</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>993</td>\n",
              "      <td>OMB APPROVAL OMB Number: 3235-0554 Expires:  F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>997</td>\n",
              "      <td>This collection of information has been review...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>986</td>\n",
              "      <td>The exchange consents that service of any civi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>900</td>\n",
              "      <td>Exhibit D Describe the manner of operation of ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83d70a40-dee4-4aa1-859f-1d7889b1d4d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83d70a40-dee4-4aa1-859f-1d7889b1d4d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83d70a40-dee4-4aa1-859f-1d7889b1d4d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0ea9140b-5017-4961-9fa7-ef51c9a8ac19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ea9140b-5017-4961-9fa7-ef51c9a8ac19')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0ea9140b-5017-4961-9fa7-ef51c9a8ac19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final dataframe above, contains number of tokens in every content withthe respective content that we will be using to perform qa using open ai. We stored this dataframe as a csv file in google drive, too utilize in next the notebook."
      ],
      "metadata": {
        "id": "WS3iJgw4AtwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final DataFrame to a CSV file on a google drive\n",
        "df_final.to_csv(\"/content/drive/MyDrive/DAMG7245/pdf_content_openai.csv\", index=False)"
      ],
      "metadata": {
        "id": "Eef6CDcjk-f6"
      },
      "execution_count": 72,
      "outputs": []
    }
  ]
}